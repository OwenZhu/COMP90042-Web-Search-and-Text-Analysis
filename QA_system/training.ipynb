{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39809\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import model\n",
    "import constants as const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"training_data.pickle\", \"rb\") as input_file:\n",
    "    # training data is list of dictionary\n",
    "    training_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "training_data = shuffle(training_data, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n",
      "(?, ?, 50)\n",
      "similarity: Tensor(\"question_context_attention/MatMul:0\", shape=(?, ?, ?), dtype=float32)\n",
      "(?, ?, 128)\n",
      "(?, ?, 128)\n",
      "(?, ?, 128)\n",
      "WARNING:tensorflow:From C:\\Users\\39809\\Documents\\QA_system\\model.py:80: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emb_mat = np.load(\"word_embedding_matrix.npy\")\n",
    "\n",
    "edm = model.EncoderDecoderModel(emb_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vocabulary.pickle\", \"rb\") as input_file:\n",
    "    voc = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_max_length(lst):\n",
    "    length = max((len(e) for e in lst))\n",
    "    return length\n",
    "\n",
    "def convert_word_to_embedding_index(word, voc):\n",
    "    if word in voc:\n",
    "        return voc[word]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    writer = tf.summary.FileWriter('model/train', sess.graph)\n",
    "    \n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'model/rnn')\n",
    "    \n",
    "    batch_i = 0\n",
    "    for epoch in range(10):\n",
    "        training_data = shuffle(training_data)\n",
    "        while batch_i < len(training_data):\n",
    "            start = batch_i\n",
    "            end = batch_i + const.BATCH_SIZE\n",
    "            q_list = []\n",
    "            c_list = []\n",
    "            s_list = []\n",
    "            e_list = []\n",
    "            for ins in training_data[start: end]:\n",
    "                q_list.append(list(map(lambda x: convert_word_to_embedding_index(x, voc), ins['question'])))\n",
    "                c_list.append(list(map(lambda x: convert_word_to_embedding_index(x, voc), ins['context'])))\n",
    "                s_list.append(ins['start'])\n",
    "                e_list.append(ins['end'])\n",
    "            \n",
    "            # padding to a matrix by '0'\n",
    "            max_q = find_max_length(q_list)\n",
    "            for i in q_list:\n",
    "                i.extend([0] * (max_q - len(i)))\n",
    "            batch_q = np.asarray(q_list)\n",
    "            \n",
    "            max_c = find_max_length(c_list)\n",
    "            for i in c_list:\n",
    "                i.extend([0] * (max_c - len(i)))\n",
    "            batch_c = np.asarray(c_list)\n",
    "            \n",
    "            max_s = find_max_length(s_list)\n",
    "            for i in s_list:\n",
    "                i.extend([0] * (max_s - len(i)))\n",
    "            batch_s = np.asarray(s_list)\n",
    "            \n",
    "            max_e = find_max_length(e_list)\n",
    "            for i in e_list:\n",
    "                i.extend([0] * (max_e - len(i)))\n",
    "            batch_e = np.asarray(e_list)\n",
    "\n",
    "\n",
    "            _, loss, summaries = sess.run([edm.opm, edm.loss, edm.merged], feed_dict={edm.context_input: batch_c,\n",
    "                                                              edm.question_input: batch_q,\n",
    "                                                              edm.label_start: batch_s,\n",
    "                                                              edm.label_end: batch_e,\n",
    "                                                              edm.dropout_keep_prob: 0.5\n",
    "                                                              })\n",
    "\n",
    "            writer.write(summaries, batch_i)\n",
    "            \n",
    "            print(\"Epoch:\", epoch, \"loss:\", loss)\n",
    "            batch_i += const.BATCH_SIZE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
