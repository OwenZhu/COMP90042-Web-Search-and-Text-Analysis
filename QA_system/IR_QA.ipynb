{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing_data.pickle\", \"rb\") as input_file:\n",
    "    testing_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mat = np.load(\"word_embedding_matrix.npy\").astype(np.float)\n",
    "\n",
    "with open(\"vocabulary.pickle\", \"rb\") as input_file:\n",
    "    voc = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.pickle\", \"rb\") as input_file:\n",
    "    training_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': ['how', 'many', 'people', 'watched', 'the', 'apollo', '11', 'landing', '?'], 'context': ['the', 'landing', 'of', 'apollo', '11', 'was', 'an', 'event', 'watched', 'by', 'over', '500', 'million', 'people', 'around', 'the', 'world', 'and', 'is', 'widely', 'recognized', 'as', 'one', 'of', 'the', 'defining', 'moments', 'of', 'the', '20th', 'century', '.'], 'start': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'end': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word, voc, e_mat):\n",
    "    if word in voc:\n",
    "        return e_mat[voc[word], :]\n",
    "    else:\n",
    "        return e_mat[0, :]\n",
    "\n",
    "def get_tokenize_sentences(documents):\n",
    "    tokens = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        sents = nltk.sent_tokenize(doc)\n",
    "        for sent in sents:\n",
    "            sent = sent.strip(\".\")\n",
    "            sent = re.sub(r'[,;\":\\']', '', sent)\n",
    "            tokens.extend(nltk.word_tokenize(sent) )\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def get_sent_embedding(sent, voc, emb_mat):\n",
    "    sent_embedding = np.zeros((len(sent), 50))\n",
    "    for i, word in enumerate(sent):\n",
    "        word_embedding = get_word_embedding(word, voc, emb_mat)\n",
    "        sent_embedding[i, :] = word_embedding\n",
    "\n",
    "    sent_embedding = np.mean(sent_embedding, axis=0)\n",
    "    return sent_embedding\n",
    "    \n",
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93490492 0.90168545 0.92828754 0.91339167 0.86186674 0.82032573\n",
      " 0.91350028 0.9100018 ]\n",
      "[0.91581718 0.88284843 0.90909996 0.87392492 0.83246396 0.92219867\n",
      " 0.91817481 0.90499963]\n",
      "[0.9653651  0.94495417 0.98542792 0.97842912 0.94061607 0.9662019\n",
      " 0.89187433 0.95549378 0.9673979  0.97011311 0.97152908 0.8997807 ]\n"
     ]
    }
   ],
   "source": [
    "test_ans = []\n",
    "\n",
    "for t in testing_data[:3]:\n",
    "    ans = dict()\n",
    "    tokenize_sentences = get_tokenize_sentences(t['text'])\n",
    "    tokenize_question = get_tokenize_sentences([t['question']])\n",
    "    q_emb = get_sent_embedding(tokenize_question[0], voc, emb_mat)\n",
    "\n",
    "    sims = np.zeros((len(tokenize_sentences)))\n",
    "    for i, sent in enumerate(tokenize_sentences):\n",
    "        s_emb = get_sent_embedding(sent, voc, emb_mat)\n",
    "        sims[i] = cos_sim(q_emb, s_emb)\n",
    "    \n",
    "    print(sims)\n",
    "    sentences = []\n",
    "    for para in t['text']:\n",
    "        sentences.extend(nltk.sent_tokenize(para))\n",
    "    \n",
    "    ans[\"id\"] = t['id']\n",
    "    ans['question'] = t['question']\n",
    "    ans[\"text\"] = sentences[np.argmax(sims)]\n",
    "    test_ans.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"devel.json\"\n",
    "with open(file_name) as json_data:\n",
    "    devel_set = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What can adult learners obtain through studying at the Edwards Campus of the University of Kansas?', 'id': 2000, 'text': ['The University of Kansas School of Business is a public business school located on the main campus of the University of Kansas in Lawrence, Kansas.']}\n"
     ]
    }
   ],
   "source": [
    "print(testing_data[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(tree, tag=\"NP\"):\n",
    "    \"recursively traverses an nltk.tree.Tree to find named entities\"\n",
    "\n",
    "    items = []\n",
    "\n",
    "    if hasattr(tree, 'label') and tree.label:\n",
    "        if tree.label() == tag:\n",
    "            items.append(' '.join([child[0] for child in tree]))\n",
    "        else:\n",
    "            for child in tree:\n",
    "                items.extend(traverse(child))\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Modern browser support standards-based and defacto what?', 'id': 0, 'text': ' Modern web browsers support a combination of standards-based and de facto HTML and XHTML, which should be rendered in the same way by all browsers. In 1998, Netscape launched what was to become the Mozilla Foundation in an attempt to produce a competitive browser using the open source software model.'}\n",
      "[('Mozilla', 'ORGANIZATION'), ('Foundation', 'ORGANIZATION')]\n",
      "['Modern web browsers', 'a combination', 'HTML', 'XHTML', 'the same way', 'all browsers', '1998', 'Netscape', 'the Mozilla Foundation', 'an attempt', 'a competitive browser', 'the open source software model']\n",
      "{'question': 'What do people typically call a web browser?', 'id': 1, 'text': ' A browser extension is a computer program that extends the functionality of a web browser. In 1998, Netscape launched what was to become the Mozilla Foundation in an attempt to produce a competitive browser using the open source software model.'}\n",
      "[('Mozilla', 'ORGANIZATION'), ('Foundation', 'ORGANIZATION')]\n",
      "['A browser extension', 'a computer program', 'the functionality', 'a web browser', '1998', 'Netscape', 'the Mozilla Foundation', 'an attempt', 'a competitive browser', 'the open source software model']\n",
      "{'question': 'What is it called when content is changed from markup to an interactive document?', 'id': 2, 'text': ' is passed to the browser\\'s layout engine to be transformed from markup to an interactive document, a process known as \"rendering\". When a link is clicked, the browser navigates to the resource indicated by the link\\'s target URI, and the process of bringing content to the user begins again.'}\n",
      "[]\n",
      "['the browsers', 'engine', 'markup', 'an interactive document', 'a process', 'a link', 'the browser', 'the resource', 'the links', 'URI', 'the process', 'content', 'the user']\n",
      "{'question': 'What platform is a browser used on?', 'id': 3, 'text': ' A web browser (commonly referred to as a browser) is a software application for retrieving, presenting, and traversing information resources on the World Wide Web. A browser extension is a computer program that extends the functionality of a web browser.'}\n",
      "[]\n",
      "['A web browser', 'a browser', 'a software application', 'presenting', 'information resources', 'the World Wide Web A browser extension', 'a computer program', 'the functionality', 'a web browser']\n",
      "{'question': 'When was Firefox released?', 'id': 4, 'text': ' That browser would eventually evolve into Firefox, which developed a respectable following while still in the beta stage of development; shortly after the release of Firefox 1.0 in late 2004, Firefox (all versions) accounted for 7% of browser use. For example, Google pays Mozilla, the maker of Firefox, to make Google Search the default search engine in Firefox.'}\n",
      "[('Firefox', 'ORGANIZATION'), ('Google', 'ORGANIZATION'), ('Mozilla', 'ORGANIZATION'), ('Firefox', 'ORGANIZATION'), ('Google', 'ORGANIZATION')]\n",
      "['That browser', 'Firefox', 'a respectable following', 'the beta stage', 'development', 'the release', 'Firefox', '1.0', '2004', 'Firefox', 'all versions', '7', '%', 'browser use', 'example Google', 'Mozilla', 'the maker', 'Firefox', 'Google Search', 'the default search engine', 'Firefox']\n",
      "{'question': 'Who released the Internet Explorer browser?', 'id': 5, 'text': ' Bundled with Windows, Internet Explorer gained dominance in the web browser market; Internet Explorer usage share peaked at over 95% by 2002. In December 2011, Chrome overtook Internet Explorer 8 as the most widely used web browser but still had lower usage than all versions of Internet Explorer combined.'}\n",
      "[]\n",
      "['Windows Internet Explorer', 'dominance', 'the web browser market Internet Explorer', 'usage share', '95', '%', '2002', 'December', '2011', 'Chrome', 'Internet Explorer', '8', 'web browser', 'usage', 'all versions', 'Internet Explorer']\n",
      "{'question': 'When was the first browser created?', 'id': 6, 'text': ' The first web browser was invented in 1990 by Sir Tim Berners-Lee. In 1993, browser software was further innovated by Marc Andreessen with the release of Mosaic, \"the world\\'s first popular browser\", which made the World Wide Web system easy to use and more accessible to the average person.'}\n",
      "[('Tim', 'PERSON'), ('Berners-Lee', 'PERSON'), ('Marc', 'PERSON'), ('Andreessen', 'PERSON')]\n",
      "['The first web browser', '1990', 'Sir Tim Berners-Lee', '1993', 'browser software', 'Marc Andreessen', 'the release', 'Mosaic', 'the worlds', 'popular browser', 'the World Wide Web system', 'the average person']\n",
      "{'question': 'HTTP Secure is supported by what?', 'id': 7, 'text': ' Early web browsers supported only a very simple version of HTML. The most commonly used kind of URI starts with http: and identifies a resource to be retrieved over the Hypertext Transfer Protocol (HTTP).'}\n",
      "[]\n",
      "['Early web browsers', 'simple version', 'HTML', 'kind', 'URI', 'http', 'a resource', 'the Hypertext Transfer Protocol', 'HTTP']\n",
      "{'question': 'Who released Mosaic?', 'id': 8, 'text': \" The most recent major entrant to the browser market is Chrome, first released in September 2008. Andreessen, the leader of the Mosaic team at National Center for Supercomputing Applications (NCSA), soon started his own company, named Netscape, and released the Mosaic-influenced Netscape Navigator in 1994, which quickly became the world's most popular browser, accounting for 90% of all web use at its peak (see usage share of web browsers).\"}\n",
      "[('Andreessen', 'PERSON'), ('National', 'ORGANIZATION'), ('Center', 'ORGANIZATION'), ('for', 'ORGANIZATION'), ('Supercomputing', 'ORGANIZATION'), ('Applications', 'ORGANIZATION'), ('Netscape', 'ORGANIZATION'), ('Netscape', 'ORGANIZATION'), ('Navigator', 'ORGANIZATION')]\n",
      "['recent major entrant', 'the browser market', 'Chrome', 'September', '2008', 'Andreessen', 'the leader', 'the Mosaic team', 'National Center', 'Applications', 'NCSA', 'own company', 'Netscape', 'the Mosaic-influenced Netscape Navigator', '1994', 'the worlds', 'popular browser accounting', '90', '%', 'all web use', 'peak', 'usage share', 'web browsers']\n",
      "{'question': 'Who invented the first browser?', 'id': 9, 'text': ' The first web browser was invented in 1990 by Sir Tim Berners-Lee. The most recent major entrant to the browser market is Chrome, first released in September 2008.'}\n",
      "[('Tim', 'PERSON'), ('Berners-Lee', 'PERSON')]\n",
      "['The first web browser', '1990', 'Sir Tim Berners-Lee', 'recent major entrant', 'the browser market', 'Chrome', 'September', '2008']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "test_ans = []\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NUM:\n",
    "    {<CD>}\n",
    "  NP:\n",
    "    {<DT>?<JJ>*<NN.*>+}\n",
    "\"\"\"\n",
    "\n",
    "snt = StanfordNERTagger('/home/ubuntu/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz') \n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "for t in testing_data[:10]:\n",
    "    answer = dict()\n",
    "    answer[\"id\"] = t['id']\n",
    "    \n",
    "    query = t[\"question\"].lower()\n",
    "    \n",
    "    tokens = get_tokenize_sentences([t[\"text\"]])\n",
    "    ner_tag = snt.tag(tokens)\n",
    "    \n",
    "    persons = []\n",
    "    for e in ner_tag:\n",
    "        if e[1] == 'O':\n",
    "            entities.append(e)\n",
    "    print(entities)\n",
    "    \n",
    "    pos_tokens = nltk.pos_tag(tokens)\n",
    "    tree = cp.parse(pos_tokens)\n",
    "    \n",
    "    if \"who\" in query:\n",
    "        answer[\"text\"]\n",
    "        pass\n",
    "    elif \"when\" in query:\n",
    "        NPs = traverse(tree, \"NUM\")\n",
    "        if not NPs:\n",
    "            NPs = \n",
    "        pass\n",
    "    elif \"where\" in query:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    test_ans.append(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29a65b69cfa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id,answer\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpos_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_data' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('test.csv', 'w') as f:\n",
    "    f.write(\"id,answer\\n\")\n",
    "    for t in testing_data:\n",
    "        pos_sent = nltk.pos_tag(nltk.word_tokenize(t['text'][0]))\n",
    "        tree = cp.parse(pos_sent)\n",
    "        ans = traverse(tree)\n",
    "        entities = snt.tag(traverse(tree))\n",
    "        \n",
    "        ans = \" \".join(ans)\n",
    "        ans = re.sub(r'[^\\w\\s]', '', ans)\n",
    "        f.write(str(t['id']) + ',' + ans + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
