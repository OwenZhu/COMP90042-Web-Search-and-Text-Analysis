{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mat = np.load(\"word_embedding_matrix.npy\").astype(np.float)\n",
    "\n",
    "with open(\"vocabulary.pickle\", \"rb\") as input_file:\n",
    "    voc = pickle.load(input_file)\n",
    "    \n",
    "with open(\"testing_data.pickle\", \"rb\") as input_file:\n",
    "    testing_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_word_embedding(word, voc, e_mat):\n",
    "    if word in voc:\n",
    "        return e_mat[voc[word], :]\n",
    "    else:\n",
    "        return e_mat[0, :]\n",
    "\n",
    "def get_tokenize_sentences(documents):\n",
    "    sentences = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        sentences.extend(nltk.sent_tokenize(doc))\n",
    "\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    return sentences\n",
    "\n",
    "def get_sent_embedding(sent, voc, emb_mat):\n",
    "    sent_embedding = np.zeros((len(sent), 50))\n",
    "    for i, word in enumerate(sent):\n",
    "        word_embedding = get_word_embedding(word, voc, emb_mat)\n",
    "        sent_embedding[i, :] = word_embedding\n",
    "\n",
    "    sent_embedding = np.mean(sent_embedding, axis=0)\n",
    "    return sent_embedding\n",
    "    \n",
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for t in testing_data:\n",
    "    ans = dict()\n",
    "    tokenize_sentences = get_tokenize_sentences(t['text'])\n",
    "    tokenize_question = get_tokenize_sentences([t['question']])\n",
    "    q_emb = get_sent_embedding(tokenize_question[0], voc, emb_mat)\n",
    "\n",
    "    sims = np.zeros((len(tokenize_sentences)))\n",
    "    for i, sent in enumerate(tokenize_sentences):\n",
    "        s_emb = get_sent_embedding(sent, voc, emb_mat)\n",
    "        sims[i] = cos_sim(q_emb, s_emb)\n",
    "    \n",
    "    sentences = []\n",
    "    for para in t['text']:\n",
    "        sentences.extend(nltk.sent_tokenize(para))\n",
    "    \n",
    "    ans[\"id\"] = t['id']\n",
    "    ans[\"text\"] = sentences[np.argmax(sims)]\n",
    "    \n",
    "    test_ans.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    chunked_sentences = nltk.ne_chunk_sents(sentences, binary=True)\n",
    "    return chunked_sentences\n",
    "\n",
    "def find_entities(chunks):\n",
    "    \"given list of tagged parts of speech, returns unique named entities\"\n",
    "\n",
    "    def traverse(tree):\n",
    "        \"recursively traverses an nltk.tree.Tree to find named entities\"\n",
    "          \n",
    "        entity_names = []\n",
    "    \n",
    "        if hasattr(tree, 'label') and tree.label:\n",
    "            if tree.label() == 'NE':\n",
    "                entity_names.append(' '.join([child[0] for child in tree]))\n",
    "            else:\n",
    "                for child in tree:\n",
    "                    entity_names.extend(traverse(child))\n",
    "    \n",
    "        return entity_names\n",
    "    \n",
    "    named_entities = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        print(chunk)\n",
    "        entities = sorted(list(set([word for tree in chunk for word in traverse(tree)])))\n",
    "        for e in entities:\n",
    "            if e not in named_entities:\n",
    "                named_entities.append(e)\n",
    "                \n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"devel.json\"\n",
    "with open(file_name) as json_data:\n",
    "    devel_set = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Modern browser support standards-based and defacto what?', 'id': 0, 'text': ['Early web browsers supported only a very simple version of HTML. The rapid development of proprietary web browsers led to the development of non-standard dialects of HTML, leading to problems with interoperability. Modern web browsers support a combination of standards-based and de facto HTML and XHTML, which should be rendered in the same way by all browsers.', 'In 1998, Netscape launched what was to become the Mozilla Foundation in an attempt to produce a competitive browser using the open source software model. That browser would eventually evolve into Firefox, which developed a respectable following while still in the beta stage of development; shortly after the release of Firefox 1.0 in late 2004, Firefox (all versions) accounted for 7% of browser use. As of August 2011, Firefox has a 28% usage share.', 'Available web browsers range in features from minimal, text-based user interfaces with bare-bones support for HTML to rich user interfaces supporting a wide variety of file formats and protocols. Browsers which include additional components to support e-mail, Usenet news, and Internet Relay Chat (IRC), are sometimes referred to as \"Internet suites\" rather than merely \"web browsers\".']}\n"
     ]
    }
   ],
   "source": [
    "print(testing_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Early/JJ\n",
      "  web/NN\n",
      "  browsers/NNS\n",
      "  supported/VBD\n",
      "  only/RB\n",
      "  a/DT\n",
      "  very/RB\n",
      "  simple/JJ\n",
      "  version/NN\n",
      "  of/IN\n",
      "  (NE HTML/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  rapid/JJ\n",
      "  development/NN\n",
      "  of/IN\n",
      "  proprietary/JJ\n",
      "  web/NN\n",
      "  browsers/NNS\n",
      "  led/VBD\n",
      "  to/TO\n",
      "  the/DT\n",
      "  development/NN\n",
      "  of/IN\n",
      "  non-standard/JJ\n",
      "  dialects/NNS\n",
      "  of/IN\n",
      "  (NE HTML/NNP)\n",
      "  ,/,\n",
      "  leading/VBG\n",
      "  to/TO\n",
      "  problems/NNS\n",
      "  with/IN\n",
      "  interoperability/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (NE Modern/NNP)\n",
      "  web/NN\n",
      "  browsers/NNS\n",
      "  support/VBP\n",
      "  a/DT\n",
      "  combination/NN\n",
      "  of/IN\n",
      "  standards-based/JJ\n",
      "  and/CC\n",
      "  de/FW\n",
      "  facto/FW\n",
      "  (NE HTML/NNP)\n",
      "  and/CC\n",
      "  (NE XHTML/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  should/MD\n",
      "  be/VB\n",
      "  rendered/VBN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  way/NN\n",
      "  by/IN\n",
      "  all/DT\n",
      "  browsers/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  In/IN\n",
      "  1998/CD\n",
      "  ,/,\n",
      "  (NE Netscape/NNP)\n",
      "  launched/VBD\n",
      "  what/WP\n",
      "  was/VBD\n",
      "  to/TO\n",
      "  become/VB\n",
      "  the/DT\n",
      "  (NE Mozilla/NNP Foundation/NNP)\n",
      "  in/IN\n",
      "  an/DT\n",
      "  attempt/NN\n",
      "  to/TO\n",
      "  produce/VB\n",
      "  a/DT\n",
      "  competitive/JJ\n",
      "  browser/NN\n",
      "  using/VBG\n",
      "  the/DT\n",
      "  open/JJ\n",
      "  source/NN\n",
      "  software/NN\n",
      "  model/NN\n",
      "  ./.)\n",
      "(S\n",
      "  That/DT\n",
      "  browser/NN\n",
      "  would/MD\n",
      "  eventually/RB\n",
      "  evolve/VB\n",
      "  into/IN\n",
      "  (NE Firefox/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  developed/VBD\n",
      "  a/DT\n",
      "  respectable/JJ\n",
      "  following/NN\n",
      "  while/IN\n",
      "  still/RB\n",
      "  in/IN\n",
      "  the/DT\n",
      "  beta/NN\n",
      "  stage/NN\n",
      "  of/IN\n",
      "  development/NN\n",
      "  ;/:\n",
      "  shortly/RB\n",
      "  after/IN\n",
      "  the/DT\n",
      "  release/NN\n",
      "  of/IN\n",
      "  Firefox/NNP\n",
      "  1.0/CD\n",
      "  in/IN\n",
      "  late/JJ\n",
      "  2004/CD\n",
      "  ,/,\n",
      "  (NE Firefox/NNP)\n",
      "  (/(\n",
      "  all/DT\n",
      "  versions/NNS\n",
      "  )/)\n",
      "  accounted/VBD\n",
      "  for/IN\n",
      "  7/CD\n",
      "  %/NN\n",
      "  of/IN\n",
      "  browser/NN\n",
      "  use/NN\n",
      "  ./.)\n",
      "(S\n",
      "  As/IN\n",
      "  of/IN\n",
      "  August/NNP\n",
      "  2011/CD\n",
      "  ,/,\n",
      "  (NE Firefox/NNP)\n",
      "  has/VBZ\n",
      "  a/DT\n",
      "  28/CD\n",
      "  %/NN\n",
      "  usage/JJ\n",
      "  share/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Available/JJ\n",
      "  web/NN\n",
      "  browsers/NNS\n",
      "  range/VBP\n",
      "  in/IN\n",
      "  features/NNS\n",
      "  from/IN\n",
      "  minimal/JJ\n",
      "  ,/,\n",
      "  text-based/JJ\n",
      "  user/NN\n",
      "  interfaces/NNS\n",
      "  with/IN\n",
      "  bare-bones/JJ\n",
      "  support/NN\n",
      "  for/IN\n",
      "  (NE HTML/NNP)\n",
      "  to/TO\n",
      "  rich/VB\n",
      "  user/JJ\n",
      "  interfaces/NNS\n",
      "  supporting/VBG\n",
      "  a/DT\n",
      "  wide/JJ\n",
      "  variety/NN\n",
      "  of/IN\n",
      "  file/NN\n",
      "  formats/NNS\n",
      "  and/CC\n",
      "  protocols/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Browsers/NNS\n",
      "  which/WDT\n",
      "  include/VBP\n",
      "  additional/JJ\n",
      "  components/NNS\n",
      "  to/TO\n",
      "  support/VB\n",
      "  e-mail/NN\n",
      "  ,/,\n",
      "  (NE Usenet/NNP)\n",
      "  news/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  Internet/NNP\n",
      "  Relay/NNP\n",
      "  Chat/NNP\n",
      "  (/(\n",
      "  (NE IRC/NNP)\n",
      "  )/)\n",
      "  ,/,\n",
      "  are/VBP\n",
      "  sometimes/RB\n",
      "  referred/VBN\n",
      "  to/TO\n",
      "  as/IN\n",
      "  ``/``\n",
      "  Internet/NNP\n",
      "  suites/NNS\n",
      "  ''/''\n",
      "  rather/RB\n",
      "  than/IN\n",
      "  merely/RB\n",
      "  ``/``\n",
      "  web/JJ\n",
      "  browsers/NNS\n",
      "  ''/''\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "for t in testing_data[:1]:\n",
    "    for para in t['text']:\n",
    "        find_entities(ie_preprocess(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('test.csv', 'w') as f:\n",
    "    f.write(\"id,answer\\n\")\n",
    "    for t in test_ans:\n",
    "        ans = t['text'].strip()\n",
    "        ans = find_entities(ie_preprocess(ans))\n",
    "        if not ans:\n",
    "            ans = t['text'].strip()\n",
    "        else:\n",
    "            ans = \" \".join(ans)\n",
    "        ans = re.sub(r'[^\\w\\s]', '', ans)\n",
    "        f.write(str(t['id']) + ',' + ans + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
